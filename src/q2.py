# -*- coding: utf-8 -*-
"""q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RDSqSugLzSQ4plWueb7sEChigIh9shcs
"""

import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning) 
from google.colab import drive

drive.mount('/content/drive')

import os
import glob
trainingPath = '/content/drive/My Drive/MCAAssignment2/Dataset/training'

def dictionaryTitles(path):
    '''returns all folders in training set'''
    image_files = sorted([os.path.join(path, '', file)
                          for file in os.listdir(path)
                          ])
    return image_files
pathOfFolders = dictionaryTitles(trainingPath)


zero = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/zero'
for filename in glob.glob(os.path.join(path, '*.wav')):
    zero[filename] = ""
#print(zero)

one = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/one'
for filename in glob.glob(os.path.join(path, '*.wav')):
    one[filename] = ""

two = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/two'
for filename in glob.glob(os.path.join(path, '*.wav')):
    two[filename] = ""

three = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/three'
for filename in glob.glob(os.path.join(path, '*.wav')):
    three[filename] = ""

four = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/four'
for filename in glob.glob(os.path.join(path, '*.wav')):
    four[filename] = ""

five = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/five'
for filename in glob.glob(os.path.join(path, '*.wav')):
    five[filename] = ""

six = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/six'
for filename in glob.glob(os.path.join(path, '*.wav')):
    six[filename] = ""

seven = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/seven'
for filename in glob.glob(os.path.join(path, '*.wav')):
    seven[filename] = ""

eight = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/eight'
for filename in glob.glob(os.path.join(path, '*.wav')):
    eight[filename] = ""

nine = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/training/nine'
for filename in glob.glob(os.path.join(path, '*.wav')):
    nine[filename] = ""

fname = "/content/drive/My Drive/MCAAssignment2/Dataset/training/zero/004ae714_nohash_0.wav"
import wave
import contextlib
ts = 0
with contextlib.closing(wave.open(fname,'r')) as f:
    frames = f.getnframes()
    rate = f.getframerate()
    duration = frames / float(rate)
    ts = duration

a = next(iter(zero))
print(a)

#MY CODE
from scipy.io import wavfile
import numpy
def getTimeSeries(fileName):
  samplerate, data = wavfile.read(fileName)
  times = np.arange(len(data))/float(samplerate)
  return times

ts = getTimeSeries(fname)
print(getTimeSeries(fname))

def mfcc_filter_banks(sampling_rate, num_fft, lowfreq=133.33, linc=200 / 3,
                      logsc=1.0711703, num_lin_filt=13, num_log_filt=27):
    """
    Computes the triangular filterbank for MFCC computation 
    (used in the stFeatureExtraction function before the stMFCC function call)
    This function is taken from the scikits.talkbox library (MIT Licence):
    https://pypi.python.org/pypi/scikits.talkbox
    """


    # Total number of filters
    var = num_lin_filt #Linear Filters
    var2 = num_log_filt #Log Filters
    varFin = var + var2 #Sum of filters
    num_filt_total = varFin # Total filters variable

    # Compute frequency points of the triangle:
    a = num_filt_total + 2
    frequencies = np.zeros(a)

    b = np.arrange(num_lin_filt)
    c = b*linc
    d = lowfreq + c
    frequencies[:num_lin_filt] = d

    temp = num_lin_filt - 1
    temp2 = num_log_filt + 3
    frequencies[num_lin_filt:] = frequencies[temp] * logsc ** \
                                 np.arange(1, temp2)
    heights = 2. / (frequencies[2:] - frequencies[0:-2])

    # Compute filterbank coeff (in fft domain, in bins)
    fbank = np.zeros((var+var2, num_fft))
    nfreqs = np.arange(num_fft) / (1. * num_fft) * sampling_rate

    for i in range(var+var2):
        low_freqs = frequencies[i]

        forCent = i+1
        cent_freqs = frequencies[forCent]

        forHigh = i+2
        high_freqs = frequencies[forHigh]

        u =  low_freqs * num_fft
        floor1 = u/sampling_rate
        v = cent_freqs * num_fft
        floor2 = v / sampling_rate
        lid = np.arange(np.floor(floor1) + 1,
                        np.floor(floor2) + 1,
                        dtype=np.int)
        
        difference = cent_freqs - low_freqs
        lslope = heights[i] / (difference)

        u = cent_freqs * num_fft
        floor1 = u / sampling_rate
        v = high_freqs * num_fft
        floor2 = v/ sampling_rate
        rid = np.arange(np.floor( floor1) + 1,
                        np.floor( floor2) + 1,
                        dtype=np.int)
        
        difference = high_freqs - cent_freqs
        rslope = heights[i] / (difference)
        
        try:
          a = nfreqs[lid]
          a = a - low_freqs
          fbank[i][lid] = lslope * (a)

          b = high_freqs
          fbank[i][rid] = rslope * (high_freqs - nfreqs[rid])
        except:
          continue
        

    return fbank, frequencies

def mfcc(fft_magnitude, fbank, num_mfcc_feats):
    mspec = np.log10(np.dot(fft_magnitude, fbank.T) + eps)
    ceps = dct(mspec, type=2, norm='ortho', axis=-1)[:num_mfcc_feats]
    return ceps

from scipy.fftpack import fft
from scipy.signal import lfilter
from scipy.fftpack.realtransforms import dct
## CREDITS: https://github.com/tyiannak/pyAudioAnalysis/blob/master/pyAudioAnalysis/ShortTermFeatures.py
eps = 0.00000001
def feature_extraction(signal, sampling_rate, window, step, deltas=True):
    window = int(window)
    step = int(step)

    # signal normalization
    signal = np.double(signal)
    signal = signal / (2.0 ** 15)
    dc_offset = signal.mean()
    signal_max = (np.abs(signal)).max()
    signal = (signal - dc_offset) / (signal_max + 0.0000000001)

    number_of_samples = len(signal)  # total number of samples
    current_position = 0
    count_fr = 0
    num_fft = int(window / 2)

    # compute the triangular filter banks used in the mfcc calculation
    fbank, freqs = mfcc_filter_banks(sampling_rate, num_fft)

    # n_time_spectral_feats = 8
    # n_harmonic_feats = 0
    n_mfcc_feats = 13
    # n_chroma_feats = 13
    n_total_feats = 13
    #    n_total_feats = n_time_spectral_feats + n_mfcc_feats +
    #    n_harmonic_feats

    # define list of feature names
    
    #     feature_names = feature_names_2

    features = []
    # for each short-term window to end of signal
    while current_position + window - 1 < number_of_samples:
        count_fr += 1
        # get current window
        x = signal[current_position:current_position + window]

        # update window position
        current_position = current_position + step

        # get fft magnitude
        fft_magnitude = abs(fft(x))

        # normalize fft
        fft_magnitude = fft_magnitude[0:num_fft]
        fft_magnitude = fft_magnitude / len(fft_magnitude)

        # keep previous fft mag (used in spectral flux)
        if count_fr == 1:
            fft_magnitude_previous = fft_magnitude.copy()
        feature_vector = np.zeros((n_total_feats, 1))

        # # zero crossing rate
        # feature_vector[0] = zero_crossing_rate(x)

        # # short-term energy
        # feature_vector[1] = energy(x)

        # # short-term entropy of energy
        # feature_vector[2] = energy_entropy(x)

        
        mffc_feats_end =  n_mfcc_feats
        feature_vector[0:mffc_feats_end, 0] = mfcc(fft_magnitude, fbank, n_mfcc_feats).copy()

        # chroma features
        # chroma_names, chroma_feature_matrix = \
        #     chroma_features(fft_magnitude, sampling_rate, num_fft)
        # chroma_features_end = n_time_spectral_feats + n_mfcc_feats + \
        #                       n_chroma_feats - 1
        # feature_vector[mffc_feats_end:chroma_features_end] = \
        #     chroma_feature_matrix
        # feature_vector[chroma_features_end] = chroma_feature_matrix.std()
        # if not deltas:
        features.append(feature_vector)
        # else:
        #     # delta features
        #     if count_fr > 1:
        #         delta = feature_vector - feature_vector_prev
        #         feature_vector_2 = np.concatenate((feature_vector, delta))
        #     else:
        #         feature_vector_2 = np.concatenate((feature_vector,
        #                                            np.zeros(feature_vector.
        #                                                     shape)))
        #     feature_vector_prev = feature_vector
        #     features.append(feature_vector_2)

        fft_magnitude_previous = fft_magnitude.copy()

    # features = np.concatenate(features, 1)
    return features

i=1
for key in zero:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  zero[key]=spec
  print(key)
  print(i)
  i=i+1
for key in one:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  one[key]=spec
  print(key)
  print(i)
  i=i+1
for key in two:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  two[key]=spec
  print(key)
  print(i)
  i=i+1
for key in three:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  three[key]=spec
  print(key)
  print(i)
  i=i+1
for key in four:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  four[key]=spec
  print(key)
  print(i)
  i=i+1
for key in five:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  five[key]=spec
  print(key)
  print(i)
  i=i+1
for key in six:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  six[key]=spec
  print(key)
  print(i)
  i=i+1
for key in seven:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  seven[key]=spec
  print(key)
  print(i)
  i=i+1
for key in eight:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  eight[key]=spec
  print(key)
  print(i)
  i=i+1
for key in nine:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  nine[key]=spec
  print(key)
  print(i)
  i=i+1

# import pickle
# f = open("zeroMFCC.pkl","wb")
# pickle.dump(zero,f)
# f.close()
# f = open("oneMFCC.pkl","wb")
# pickle.dump(one,f)
# f.close()
# f = open("twoMFCC.pkl","wb")
# pickle.dump(two,f)
# f.close()
# f = open("threeMFCC.pkl","wb")
# pickle.dump(three,f)
# f.close()
# f = open("fourMFCC.pkl","wb")
# pickle.dump(four,f)
# f.close()
# f = open("fiveMFCC.pkl","wb")
# pickle.dump(five,f)
# f.close()
# f = open("sixMFCC.pkl","wb")
# pickle.dump(six,f)
# f.close()
# f = open("sevenMFCC.pkl","wb")
# pickle.dump(seven,f)
# f.close()
# f = open("eightMFCC.pkl","wb")
# pickle.dump(eight,f)
# f.close()
# f = open("nineMFCC.pkl","wb")
# pickle.dump(nine,f)
# f.close()

from google.colab import files

files.download('zeroMFCC.pkl')
files.download('oneMFCC.pkl')
files.download('twoMFCC.pkl')
files.download('threeMFCC.pkl')
files.download('fourMFCC.pkl')
files.download('fiveMFCC.pkl')
files.download('sixMFCC.pkl')
files.download('sevenMFCC.pkl')
files.download('eightMFCC.pkl')
files.download('nineMFCC.pkl')

import pickle
pickle_in = open("/content/drive/My Drive/zeroMFCC.pkl","rb")
zero = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/oneMFCC.pkl","rb")
one = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/twoMFCC.pkl","rb")
two = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/threeMFCC.pkl","rb")
three = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/fourMFCC.pkl","rb")
four = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/fiveMFCC.pkl","rb")
five = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/sixMFCC.pkl","rb")
six = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/sevenMFCC.pkl","rb")
seven = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/eightMFCC.pkl","rb")
eight = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/nineMFCC.pkl","rb")
nine = pickle.load(pickle_in)

import os
import glob
ValidationPath = '/content/drive/My Drive/MCAAssignment2/Dataset/validation'

def dictionaryTitles(path):
    '''returns all folders in training set'''
    image_files = sorted([os.path.join(path, '', file)
                          for file in os.listdir(path)
                          ])
    return image_files
pathOfFolders = dictionaryTitles(trainingPath)


zeroVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/zero'
for filename in glob.glob(os.path.join(path, '*.wav')):
    zeroVal[filename] = ""
#print(zero)

oneVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/one'
for filename in glob.glob(os.path.join(path, '*.wav')):
    oneVal[filename] = ""

twoVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/two'
for filename in glob.glob(os.path.join(path, '*.wav')):
    twoVal[filename] = ""

threeVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/three'
for filename in glob.glob(os.path.join(path, '*.wav')):
    threeVal[filename] = ""

fourVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/four'
for filename in glob.glob(os.path.join(path, '*.wav')):
    fourVal[filename] = ""

fiveVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/five'
for filename in glob.glob(os.path.join(path, '*.wav')):
    fiveVal[filename] = ""

sixVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/six'
for filename in glob.glob(os.path.join(path, '*.wav')):
    sixVal[filename] = ""

sevenVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/seven'
for filename in glob.glob(os.path.join(path, '*.wav')):
    sevenVal[filename] = ""

eightVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/eight'
for filename in glob.glob(os.path.join(path, '*.wav')):
    eightVal[filename] = ""

nineVal = {}
path = '/content/drive/My Drive/MCAAssignment2/Dataset/validation/nine'
for filename in glob.glob(os.path.join(path, '*.wav')):
    nineVal[filename] = ""

i=1
print(zeroVal)
for key in zeroVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  zeroVal[key]=spec
  print(key)
  print(i)
  i=i+1
for key in oneVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  oneVal[key]=spec
  print(key)
  print(i)
  i=i+1
for key in twoVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  twoVal[key]=spec
  print(key)
  print(i)
  i=i+1
for key in threeVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  threeVal[key]=spec
  print(key)
  print(i)
  i=i+1
for key in fourVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  fourVal[key]=spec
  print(key)
  print(i)
  i=i+1
for key in fiveVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  fiveVal[key]=spec
  print(key)
  print(i)
  i=i+1
for key in sixVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  sixVal[key]=spec
  print(key)
  print(i)
  i=i+1
for key in sevenVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  sevenVal[key]=spec
  print(key)
  print(i)
  i=i+1
for key in eightVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  eightVal[key]=spec
  print(key)
  print(i)
  i=i+1
for key in nineVal:
  ts = getTimeSeries(key)
  spec = feature_extraction(ts,1200,256,100)
  nineVal[key]=spec
  print(key)
  print(i)
  i=i+1

import pickle
f = open("zeroMFCCVal.pkl","wb")
pickle.dump(zeroVal,f)
f.close()
f = open("oneMFCCVal.pkl","wb")
pickle.dump(oneVal,f)
f.close()
f = open("twoMFCCVal.pkl","wb")
pickle.dump(twoVal,f)
f.close()
f = open("threeMFCCVal.pkl","wb")
pickle.dump(threeVal,f)
f.close()
f = open("fourMFCCVal.pkl","wb")
pickle.dump(fourVal,f)
f.close()
f = open("fiveMFCCVal.pkl","wb")
pickle.dump(fiveVal,f)
f.close()
f = open("sixMFCCVal.pkl","wb")
pickle.dump(sixVal,f)
f.close()
f = open("sevenMFCCVal.pkl","wb")
pickle.dump(sevenVal,f)
f.close()
f = open("eightMFCCVal.pkl","wb")
pickle.dump(eightVal,f)
f.close()
f = open("nineMFCCVal.pkl","wb")
pickle.dump(nineVal,f)
f.close()

from google.colab import files

files.download('zeroMFCCVal.pkl')
files.download('oneMFCCVal.pkl')
files.download('twoMFCCVal.pkl')
files.download('threeMFCCVal.pkl')
files.download('fourMFCCVal.pkl')
files.download('fiveMFCCVal.pkl')
files.download('sixMFCCVal.pkl')
files.download('sevenMFCCVal.pkl')
files.download('eightMFCCVal.pkl')
files.download('nineMFCCVal.pkl')

import pickle
pickle_in = open("/content/drive/My Drive/zeroMFCCVal.pkl","rb")
zeroVal = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/oneMFCCVal.pkl","rb")
oneVal = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/twoMFCCVal.pkl","rb")
twoVal = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/threeMFCCVal.pkl","rb")
threeVal = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/fourMFCCVal.pkl","rb")
fourVal = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/fiveMFCCVal.pkl","rb")
fiveVal = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/sixMFCCVal.pkl","rb")
sixVal = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/sevenMFCCVal.pkl","rb")
sevenVal = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/eightMFCCVal.pkl","rb")
eightVal = pickle.load(pickle_in)
pickle_in = open("/content/drive/My Drive/nineMFCCVal.pkl","rb")
nineVal = pickle.load(pickle_in)

# #####65 
# a = []
# for key in zero:
#   a.append(len(zero[key]))
# print(min(a))
# a = []
# for key in one:
#   a.append(len(one[key]))
# print(min(a))
# a = []
# for key in two:
#   a.append(len(two[key]))
# print(min(a))
# a = []
# for key in three:
#   a.append(len(three[key]))
# print(min(a))
# a = []
# for key in four:
#   a.append(len(four[key]))
# print(min(a))
# a = []
# for key in five:
#   a.append(len(five[key]))
# print(min(a))
# a = []
# for key in six:
#   a.append(len(six[key]))
# print(min(a))
# a = []
# for key in seven:
#   a.append(len(seven[key]))
# print(min(a))
# a = []
# for key in eight:
#   a.append(len(eight[key]))
# print(min(a))
# a = []
# for key in nine:
#   a.append(len(nine[key]))
# print(min(a))

x = np.zeros((10000,767))

i=0
for key in zero:
  x[i]=np.asarray(zero[key]).flatten()[0:767]
  
  i=i+1
for key in one:
  try:
    x[i]=np.asarray(one[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in two:
  try:
    x[i]=np.asarray(two[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in three:
  try:
    x[i]=np.asarray(three[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in four:
  try:
    x[i]=np.asarray(four[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in five:
  try:
    x[i]=np.asarray(five[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in six:
  try:
    x[i]=np.asarray(six[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in seven:
  try:
    x[i]=np.asarray(seven[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in eight:
  try:
    x[i]=np.asarray(eight[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in nine:
  try:
    x[i]=np.asarray(nine[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1

### X dim = 10000,65

xVal = np.zeros((2494,767))

i=0
for key in zeroVal:
  # try:
  xVal[i]=np.asarray(zeroVal[key]).flatten()[0:767]
  # except:
  #   x[i]= np.zeros((1,65))
  #   print(i)
  i=i+1
for key in oneVal:
  try:
    xVal[i]=np.asarray(oneVal[key]).flatten()[0:767]
  except:
    xVal[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in twoVal:
  try:
    xVal[i]=np.asarray(twoVal[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in threeVal:
  try:
    xVal[i]=np.asarray(threeVal[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in fourVal:
  try:
    xVal[i]=np.asarray(fourVal[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in fiveVal:
  try:
    xVal[i]=np.asarray(fiveVal[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in sixVal:
  try:
    xVal[i]=np.asarray(sixVal[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in sevenVal:
  try:
    xVal[i]=np.asarray(sevenVal[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in eightVal:
  try:
    xVal[i]=np.asarray(eightVal[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1
for key in nineVal:
  try:
    xVal[i]=np.asarray(nineVal[key]).flatten()[0:767]
  except:
    x[i]= np.zeros((1,65))
    print(i)

  i=i+1

### X dim = 10000,65

# i = []
# for k in zeroVal:
#   i.append((np.asarray(zeroVal[k]).flatten().shape))
# print(min(i))
# i = []
# for k in oneVal:
#   i.append((np.asarray(oneVal[k]).flatten().shape))
# print(min(i))
# i = []
# for k in twoVal:
#   i.append((np.asarray(twoVal[k]).flatten().shape))
# print(min(i))
# i = []
# for k in threeVal:
#   i.append((np.asarray(threeVal[k]).flatten().shape))
# print(min(i))
# i = []
# for k in fourVal:
#   i.append((np.asarray(fourVal[k]).flatten().shape))
# print(min(i))
# i = []
# for k in fiveVal:
#   i.append((np.asarray(fiveVal[k]).flatten().shape))
# print(min(i))
# i = []
# for k in sixVal:
#   i.append((np.asarray(sixVal[k]).flatten().shape))
# print(min(i))
# i = []
# for k in sevenVal:
#   i.append((np.asarray(sevenVal[k]).flatten().shape))
# print(min(i))
# i = []
# for k in eightVal:
#   i.append((np.asarray(eightVal[k]).flatten().shape))
# print(min(i))
# i = []
# for k in nineVal:
#   i.append((np.asarray(nineVal[k]).flatten().shape))
# print(min(i))

y=[]
for i in range(1000):
  y.append(0)
for i in range(1000):
  y.append(1)
for i in range(1000):
  y.append(2)
for i in range(1000):
  y.append(3)
for i in range(1000):
  y.append(4)
for i in range(1000):
  y.append(5)
for i in range(1000):
  y.append(6)
for i in range(1000):
  y.append(7)
for i in range(1000):
  y.append(8)
for i in range(1000):
  y.append(9)

from sklearn import svm
clf = svm.SVC()
clf.fit(x, y)

result = clf.predict(xVal)
print(getAccuracy(result))

def getAccuracy(result):
  count = 0
  for i in range(260):
    if result[i]==0:
      count+=1
  for i in range(230):
    if result[i]==1:
      count+=1
  for i in range(236):
    if result[i]==2:
      count+=1
  for i in range(248):
    if result[i]==3:
      count+=1
  for i in range(280):
    if result[i]==4:
      count+=1
  for i in range(242):
    if result[i]==5:
      count+=1
  for i in range(262):
    if result[i]==6:
      count+=1
  for i in range(263):
    if result[i]==7:
      count+=1
  for i in range(243):
    if result[i]==8:
      count+=1
  for i in range(230):
    if result[i]==9:
      count+=1
  accuracy = float(float(count)/float(2494))
  return accuracy*100